{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 复习上课内容以及复现课程代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本部分，你需要复习上课内容和课程代码后，自己复现课程代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 回答一下理论题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What does a neuron compute?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Why we use non-linear activation funcitons in neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用线性的激活函数，无论多深的神经网络，都可以用wx+b来替代，都相当于一层的神经网络，\n",
    "这样多层的神经网络就失去了意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is the 'Logistic Loss' ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Assume that you are building a binary classifier for detecting if an image containing cats, which activation functions would you recommen using for the output layer ?\n",
    "\n",
    "A. ReLU    \n",
    "B. Leaky ReLU    \n",
    "C. sigmoid    \n",
    "D. tanh  \n",
    "\n",
    "Answer：C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Why we don't use zero initialization for all parameters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导致每个节点计算的w都是一样的，以致于一个神经元与n个神经元是一样的\n",
    "w不能初始化为零，b可以为零，一般初始化为一个比较小的值，\n",
    "因为sigmoid或者其他激活函数，当初始化太大，进行迭代由于倒数仅仅于1，会导致迭代不动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you implement the softmax function using python ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S_j = \\frac{e^ {a_j}}{\\sum_{k=1}^k e^ {a_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8360188  0.11314284 0.05083836]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
    "\n",
    "X = [3.0,1.0, 0.2]\n",
    "print(softmax(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this practical part, you will build a simple digits recognizer to check if the digit in the image is larger than 5. This assignmnet will guide you step by step to finish your first small project in this course ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Packages  \n",
    "sklearn is a famous package for machine learning.   \n",
    "matplotlib is a common package for vasualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Overvie of the dataset  \n",
    "    - a training set has m_train images labeled as 0 if the digit < 5 or 1 if the digit >= 5\n",
    "    - a test set contains m_test images labels as if the digit < 5 or 1 if the digit >= 5\n",
    "    - eah image if of shape (num_px, num_px ). Thus, each image is square(height=num_px and  width = num_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data \n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vilizating the data\n",
    "for i in range(1,11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.imshow(digits.data[i-1].reshape([8,8]),cmap=plt.cm.gray_r)\n",
    "    plt.text(3,10,str(digits.target[i-1]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training set and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64) (1347,) (450, 64) (450,)\n"
     ]
    }
   ],
   "source": [
    "# reformulate the label. \n",
    "# If the digit is smaller than 5, the label is 0.\n",
    "# If the digit is larger than 5, the label is 1.\n",
    "\n",
    "y_train[y_train < 5 ] = 0\n",
    "y_train[y_train >= 5] = 1\n",
    "y_test[y_test < 5] = 0\n",
    "y_test[y_test >= 5] = 1\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (64, 1347) y_train: (1, 1347) X_test: (64, 450) y_test: (1, 450)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_train = X_train.reshape(X_train.shape[0],-1)\\ny_train = y_train.reshape(y_train.shape[0],-1)\\nX_test = X_test.reshape(X_test.shape[0],-1)\\ny_test = y_test.reshape(y_test.shape[0],-1)\\n\\nprint(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\\n'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "\n",
    "y_train = y_train.reshape(1,-1)\n",
    "y_test = y_test.reshape(1,-1)\n",
    "print(\"X_train:\",X_train.shape,\"y_train:\",y_train.shape,\"X_test:\",X_test.shape,\"y_test:\",y_test.shape)\n",
    "'''\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "y_train = y_train.reshape(y_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "y_test = y_test.reshape(y_test.shape[0],-1)\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3- Architecture of the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical expression of the algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one example $x^{(i)}$:   \n",
    " $$ z^{(i)} = w^T * x^{(i)} +b $$   \n",
    " $$ y^{(i)} = a^{(i)} = sigmoid(z^{(i)})$$   \n",
    " $$L(a^{(i)},y^{(i)}) = -y^{(i)} log(a^{(i)})-(1-y^{(i)})log(1-a^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost over all training examples:\n",
    "$$ J = \\frac{1}{m}\\sum_{i=1}^{m}L(a^{(i)},y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Building the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1- Activation function    \n",
    "###### Exercise:\n",
    "Finish the sigmoid funciton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    '''\n",
    "    Compute the sigmoid of z\n",
    "    Arguments: z -- a scalar or numpy array of any size.\n",
    "    \n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    '''\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0,2]) = [0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "# Test your code \n",
    "# The result should be [0.5 0.88079708]\n",
    "print(\"sigmoid([0,2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1-Initializaing parameters\n",
    "###### Exercise:\n",
    "Finishe the initialize_parameters function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random innitialize the parameters\n",
    "\n",
    "def initialize_parameters(dim):\n",
    "    '''\n",
    "    Argument: dim -- size of the w vector\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim,1)\n",
    "    b -- initializaed scalar\n",
    "    '''\n",
    "    \n",
    "    #w = np.random.randn(dim,1)\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "    \n",
    "    assert(w.shape == (dim,1))\n",
    "    assert(isinstance(b,float) or isinstance(b,int))\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1) [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 0\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "w,b = initialize_parameters(X_train.shape[0])\n",
    "print(w.shape,w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3-Forward and backward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some mathematical expressions\n",
    "Forward Propagation:   \n",
    ". X    \n",
    ". A = $\\sigma(w^T*X+b) = (a^{(1)},a^{(2)},...,a^{(m)}$   \n",
    ". J = $-\\frac{1}{m} \\sum_{i=1}^{m}y^{(i)}log(a^{(i)})+(1-y^{(i)})log(1-a^{(i)})$       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some derivative: \n",
    "$$\\frac{\\partial{J}}{\\partial{w}} = \\frac{1}{m}X*(A-Y)^T$$   \n",
    "$$\\frac{\\partial{J}}{\\partial{b}} = \\frac{1}{m}\\sum_{i=1}^m(a^{(i)}-y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise:\n",
    "Finish the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    '''\n",
    "    Implement the cost function and its gradient for the propagation\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    cost = -1/m * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A) ) \n",
    "\n",
    "   \n",
    "    dw = np.dot(X,(A-Y).T)/m\n",
    "    db = np.sum(A-Y)/m\n",
    "    \n",
    "    #cost = -1/m * np.sum(np.dot(Y,np.log(A)) + np.dot(1-Y,np.log(1-A)) )\n",
    "    #print(\"cost:\",cost)\n",
    "    #print(\"w.T\",w.T.shape,\"X:\",X.shape,\"A:\",A.shape,\"Y\",Y.shape)\n",
    "    #print(\"dw:\",dw.shape,\"w:\",w.shape)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {'dw':dw,\n",
    "             'db':db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dw': array([[ 0.00000000e+00],\n",
       "         [ 5.93912398e-03],\n",
       "         [-9.31700074e-02],\n",
       "         [-9.02004454e-02],\n",
       "         [-1.35115071e-01],\n",
       "         [-7.59094284e-01],\n",
       "         [-4.62138085e-01],\n",
       "         [-5.23385301e-02],\n",
       "         [-1.48478099e-03],\n",
       "         [ 7.20118782e-02],\n",
       "         [-5.13363029e-01],\n",
       "         [ 7.98069785e-02],\n",
       "         [ 6.45879733e-01],\n",
       "         [-1.05790646e-01],\n",
       "         [-3.38901262e-01],\n",
       "         [-2.04157387e-02],\n",
       "         [ 1.11358575e-03],\n",
       "         [-7.57238307e-02],\n",
       "         [-6.67409057e-01],\n",
       "         [ 4.17223460e-01],\n",
       "         [ 9.39866370e-01],\n",
       "         [ 1.64439495e-01],\n",
       "         [ 6.90423163e-02],\n",
       "         [ 1.11358575e-02],\n",
       "         [ 3.71195249e-04],\n",
       "         [ 7.01559020e-02],\n",
       "         [-6.61469933e-01],\n",
       "         [-7.92501856e-01],\n",
       "         [-1.27691166e-01],\n",
       "         [-1.81885672e-01],\n",
       "         [ 1.82628062e-01],\n",
       "         [ 1.48478099e-03],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 3.93095768e-01],\n",
       "         [-2.92873051e-01],\n",
       "         [-7.78025241e-01],\n",
       "         [-1.29175947e-01],\n",
       "         [-1.08760208e-01],\n",
       "         [ 5.79064588e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 3.34075724e-03],\n",
       "         [ 3.44097996e-01],\n",
       "         [ 2.27171492e-01],\n",
       "         [ 1.18040089e-01],\n",
       "         [ 3.46696362e-01],\n",
       "         [ 1.06904232e-01],\n",
       "         [-2.06755754e-01],\n",
       "         [-1.33630290e-02],\n",
       "         [ 2.96956199e-03],\n",
       "         [ 7.53526355e-02],\n",
       "         [ 1.39569414e-01],\n",
       "         [ 2.05270973e-01],\n",
       "         [ 1.07498144e+00],\n",
       "         [ 5.05567929e-01],\n",
       "         [-7.79510022e-02],\n",
       "         [ 3.82331106e-02],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [-1.48478099e-01],\n",
       "         [-9.87379362e-02],\n",
       "         [ 6.21752042e-01],\n",
       "         [ 3.02895323e-01],\n",
       "         [ 2.86191537e-01],\n",
       "         [ 1.84112843e-01]]), 'db': 0.0033407572383073497}, 0.6931471805599453)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propagate(w,b,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 -Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise:\n",
    "Minimizing the cost function using gradient descent.   \n",
    "$$\\theta = \\theta - \\alpha*d\\theta$$ where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    '''\n",
    "    This function optimize w and b by running a gradient descen algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w - weights\n",
    "    b - bias\n",
    "    X - data\n",
    "    Y - ground truth\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params - dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        \n",
    "        \n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\":w,\n",
    "              \"b\":b}\n",
    "    \n",
    "    grads = {\"dw\":dw,\n",
    "             \"db\":db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "params, grads, costs = optimize(w,b,X_train,y_train,100,0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Exercise\n",
    "The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the predict() function.    \n",
    "Two steps to finish this task:   \n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T*X+b)$   \n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector Y_prediction. If you wish, you can use an if/else statement in a for loop (though there is also a way to vectorize this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias \n",
    "    X -- data \n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "\n",
    "    w = w.reshape(X.shape[0],1)\n",
    "\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0,i]>0.5:\n",
    "            Y_prediction[0,i] = 1\n",
    "        else:\n",
    "            Y_prediction[0,i] = 0\n",
    "            \n",
    "    \n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1) ()\n",
      "X_test: (64, 450)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "w_best,b_best = params['w'],params['b']\n",
    "print(w_best.shape,b_best.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "predict(w_best,b_best,X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5- Merge all functions into a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations !! You have finished all the necessary components for constructing a model. Now, Let's take the challenge to merge all the implemented function into one model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations, learning_rate,print_cost):\n",
    "    \"\"\"\n",
    "    Build the logistic regression model by calling all the functions you have implemented.\n",
    "    Arguments:\n",
    "    X_train - training set\n",
    "    Y_train - training label\n",
    "    X_test - test set\n",
    "    Y_test - test label\n",
    "    num_iteration - hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d - dictionary should contain following information w,b,training_accuracy, test_accuracy,cost\n",
    "    eg: d = {\"w\":w,\n",
    "             \"b\":b,\n",
    "             \"training_accuracy\": traing_accuracy,\n",
    "             \"test_accuracy\":test_accuracy,\n",
    "             \"cost\":cost}\n",
    "    \"\"\"\n",
    "    # initialize parameters\n",
    "    w,b = initialize_parameters(X_train.shape[0])\n",
    "    \n",
    "    # Gradient descent\n",
    "    parameters ,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
    "    \n",
    "    #best w,b\n",
    "    best_w = parameters['w']\n",
    "    best_b = parameters['b']\n",
    "    \n",
    "    #prediction\n",
    "    Y_prediction_test = predict(best_w,best_b,X_test)\n",
    "    Y_prediction_train = predict(best_w,best_b,X_train)\n",
    "    \n",
    "    traing_accuracy = 100 - np.mean(np.abs(Y_prediction_train -Y_train)*100)\n",
    "    test_accuracy = 100 - np.mean(np.abs(Y_prediction_test -Y_test)*100)\n",
    "\n",
    "    d ={\n",
    "        \"w\":best_w,\n",
    "        \"b\":best_b,\n",
    "        \"training_accuracy\": traing_accuracy,\n",
    "        \"test_accuracy\":test_accuracy,\n",
    "        \"cost\":costs}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': array([[ 0.00000000e+00],\n",
      "       [-9.60822021e-04],\n",
      "       [ 1.78320755e-03],\n",
      "       [ 2.01564999e-03],\n",
      "       [ 4.49025286e-03],\n",
      "       [ 3.83095912e-02],\n",
      "       [ 2.58946927e-02],\n",
      "       [ 2.80599007e-03],\n",
      "       [ 1.56668110e-04],\n",
      "       [-8.20331795e-03],\n",
      "       [ 2.68266839e-02],\n",
      "       [-1.22380395e-03],\n",
      "       [-3.06188001e-02],\n",
      "       [ 1.13965316e-03],\n",
      "       [ 1.65167493e-02],\n",
      "       [ 8.71025808e-04],\n",
      "       [-1.10069985e-04],\n",
      "       [ 4.45300812e-04],\n",
      "       [ 3.88048655e-02],\n",
      "       [-1.60096980e-02],\n",
      "       [-5.07580328e-02],\n",
      "       [-9.20189425e-03],\n",
      "       [-9.98496329e-03],\n",
      "       [-1.36812596e-03],\n",
      "       [-4.83066880e-05],\n",
      "       [-1.26316639e-02],\n",
      "       [ 3.36184456e-02],\n",
      "       [ 5.28598220e-02],\n",
      "       [ 9.57843210e-03],\n",
      "       [ 1.37781729e-02],\n",
      "       [-1.67283117e-02],\n",
      "       [-1.54222802e-04],\n",
      "       [ 0.00000000e+00],\n",
      "       [-3.13849336e-02],\n",
      "       [ 1.42311333e-02],\n",
      "       [ 4.64025654e-02],\n",
      "       [ 5.79451859e-03],\n",
      "       [ 4.60890313e-03],\n",
      "       [-4.35122707e-03],\n",
      "       [ 0.00000000e+00],\n",
      "       [-1.76412968e-04],\n",
      "       [-2.09583079e-02],\n",
      "       [-6.11989888e-03],\n",
      "       [-2.88017361e-03],\n",
      "       [-1.69030947e-02],\n",
      "       [-1.12986072e-03],\n",
      "       [ 1.61267359e-02],\n",
      "       [ 1.02030302e-03],\n",
      "       [-1.22569012e-04],\n",
      "       [-3.95338713e-03],\n",
      "       [-2.05793645e-03],\n",
      "       [-1.00053643e-02],\n",
      "       [-6.77909696e-02],\n",
      "       [-2.36888004e-02],\n",
      "       [ 1.21675750e-02],\n",
      "       [-1.76133895e-03],\n",
      "       [ 0.00000000e+00],\n",
      "       [-4.63796831e-04],\n",
      "       [ 3.85874698e-03],\n",
      "       [ 3.01723813e-05],\n",
      "       [-3.43158850e-02],\n",
      "       [-9.61677120e-03],\n",
      "       [-1.32996768e-02],\n",
      "       [-1.10779299e-02]]), 'b': -0.0002907510441834857, 'training_accuracy': 86.71121009651077, 'test_accuracy': 87.33333333333333, 'cost': [0.6931471805599453]}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "d = model(X_train,y_train,X_test,y_test,100,0.001,False)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.选做题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on building your first logistic regression model. It is your time to analyze it further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Observe the effect of learning rate on the leraning process.   \n",
    "Hits: plot the learning curve with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = [1e-1,1e-2,1e-3,1e-4]\n",
    "results = []\n",
    "for i in learning_rate:\n",
    "    result = model(X_train,y_train,X_test,y_test,1000,i,False)\n",
    "    results.append(result)\n",
    "\n",
    "for result in results:\n",
    "    plt.plot(np.arange(len(result['cost'])),result['cost'],label=\"cost by learning_rate {}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Observe the effect of iteration_num on the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge ! ! !\n",
    "\n",
    "The original data have images labeled 0,1,2,3,4,5,6,7,8,9. In our logistic model, we only detect if the digit in the image is larger or smaller than 5. Now, Let's go for a more challenging problem. Try to use softmax function to build a model to recognize which digits (0,1,2,3,4,5,6,7,8,9) is in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations ! You have completed assigment 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
