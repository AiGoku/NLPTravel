{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0：医院影像、自动驾驶、人脸识别、游戏机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "1:通过使用github上传同步代码，版本管理，可通过github进行上传，clone下载，或通过git进行操作 \n",
    "jupyter：简单方便、随时可以调试、可随时添加修改代码随时调试、方便机器学习调参数、方便交互、能浏览上次调试时的结果 pycharm：作为python 最大的IDLE之一，提高开发效率、代码补全、项目管理、版本控制、单元测试等等、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2:概率模型是由所有的可能的结果以及与这些结果相关的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3：正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4：基于解析和模式匹配使工作变动过于复杂，数据变动导致工作白做"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.判断一句话出现的概率，概率越接近于1，越接近于正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.语音识别、AI对话机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.统计本身汉字或词的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.该模型仅仅考虑当前词本身的概率，不考虑该词所对应的上下文环境。优点简单，易于实现，缺点是没有实际的应用价值，因为很多词的出现依赖于词的上下文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.一个词的出现仅依赖于它前面出现的词，把句子从头到尾每两个词组成一组，统计这一组出现的概率那么我们就称之为2-gram language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.设计句子生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_grammar='''\n",
    "grammar = subject adverbial_place transitive_verb adj noun  |subject adverbial_place intransitive_verb  \n",
    "subject = 我 | 孙悟空 | 龟仙人 | 比克| 饺子|界王|琪琪|库林\n",
    "verb = intransitive_verb | transitive_verb\n",
    "intransitive_verb = 受伤了|被炸了|被击倒了\n",
    "transitive_verb = 找到了|发现了|拿了|偷了|抢了|看\n",
    "adj = 一打|一把|一筐|黄色的|黑色的|红色的\n",
    "noun = 枪|子弹|金箍棒|杂志|啤酒|\n",
    "adverbial_place = 在医院|在军事基地|在海边|在泰国\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generate(gram,split='=',line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in gram.split(line_split):\n",
    "        if not line.strip():continue\n",
    "        exp,stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram,target):\n",
    "    if target not in gram: return target\n",
    "    expaned = [generate(gram,t) for t in random.choice(gram[target])]\n",
    "    result = ''.join([e for e in expaned])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram,target,count):\n",
    "    sentences = []\n",
    "    for i in range(count):\n",
    "        sentences.append(generate(gram,target))\n",
    "    print(sentences)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "饺子在医院拿了一筐啤酒\n"
     ]
    }
   ],
   "source": [
    "print(generate(create_generate(dialogue_grammar),target='grammar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['界王在海边被击倒了', '比克在医院被击倒了', '龟仙人在军事基地被炸了', '琪琪在海边被炸了', '库林在泰国被炸了', '界王在海边拿了红色的', '孙悟空在海边看红色的子弹', '我在军事基地看一筐杂志', '孙悟空在医院被炸了', '我在军事基地被炸了']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['界王在海边被击倒了',\n",
       " '比克在医院被击倒了',\n",
       " '龟仙人在军事基地被炸了',\n",
       " '琪琪在海边被炸了',\n",
       " '库林在泰国被炸了',\n",
       " '界王在海边拿了红色的',\n",
       " '孙悟空在海边看红色的子弹',\n",
       " '我在军事基地看一筐杂志',\n",
       " '孙悟空在医院被炸了',\n",
       " '我在军事基地被炸了']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(create_generate(dialogue_grammar),target='grammar',count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用新数据源完成语言模型的训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/YI/Desktop/AI/NLPTravel/movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YI/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_csv = pd.pandas.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comment = list(data_csv['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_data=re.compile('[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*“”《》：（）]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(datas):\n",
    "    cut_list= []\n",
    "    for data in datas:\n",
    "        data = re_data.sub('',str(data))\n",
    "        cut_data = list(jieba.cut(data))\n",
    "        cut_list.extend(cut_data)\n",
    "    return cut_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/3h/j8hl7pq97ld3x_hpfdlt1h580000gn/T/jieba.cache\n",
      "Loading model cost 0.994 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "TOKENS = cut(data_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_comment[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4542881"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_counter = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328267),\n",
       " ('了', 102419),\n",
       " ('是', 73106),\n",
       " ('我', 50330),\n",
       " ('都', 36255),\n",
       " ('很', 34717),\n",
       " ('看', 34032),\n",
       " ('电影', 33676),\n",
       " ('也', 32064),\n",
       " ('和', 31292)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_words = [TOKENS[i] + TOKENS[i+1] for i in range(len(TOKENS)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2_gram_words_counter = Counter(_2_gram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_counter.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gram_count(word,word_counter):\n",
    "    if word in word_counter:return word_counter[word]\n",
    "    else :return word_counter.most_common()[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_gram_model(sentence):\n",
    "    tokens = cut(sentence)\n",
    "    t_p = 1\n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        \n",
    "        two_gram_count = get_gram_count(word+next_word,_2_gram_words_counter)\n",
    "        one_gram_count = get_gram_count(word,words_counter)\n",
    "        p = two_gram_count / one_gram_count\n",
    "        \n",
    "        t_p *= p\n",
    "    return t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5425410124461593e-29"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('吴京的炒作水平不输冯小刚')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.66270903204554e-22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('这部戏让人看的热血沸腾')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.660723693051065e-35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('我觉得简直是校园青春片的一股清流')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9853189156656577e-29"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model('这是你们的青春不是我们的')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3_gram_words = [TOKENS[i] + TOKENS[i+1]+TOKENS[i+2] for i in range(len(TOKENS)-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_3_gram_words_counter = Counter(_3_gram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_gram_model(sentence):\n",
    "    tokens = cut(sentence)\n",
    "    t_p = 1\n",
    "    for i in range(len(tokens)-2):\n",
    "        one_word = tokens[i]\n",
    "        second_word = tokens[i+1]\n",
    "        third_word = tokens[i+2]\n",
    "        \n",
    "        word = one_word+second_word+third_word\n",
    "        \n",
    "        three_gram_count = get_gram_count(word,_3_gram_words_counter)\n",
    "        one_gram_count = get_gram_count(one_word,words_counter)\n",
    "        p = three_gram_count / one_gram_count\n",
    "        \n",
    "        t_p *= p\n",
    "    return t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.099261594000989e-39"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_gram_model('这是你们的青春不是我们的')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.获得最优质的的语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(gram,target,count=10,callback=three_gram_model):\n",
    "    sentences = generate_n(gram,target,count)\n",
    "    result = [(s,callback(s)) for s in sentences]\n",
    "    result = sorted(result,key=lambda x:x[1],reverse=True)\n",
    "    print(result)\n",
    "    return result[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_grammar='''\n",
    "grammar = subject verb adj noun somewhere\n",
    "subject = 我 | 你 | 她 | 他| 一帅哥|一美女|一小孩\n",
    "verb = 吃了 | 看|摸|奔跑|跳跃|喝\n",
    "adv = 高兴地|乐观地|经常\n",
    "verb = 受伤了|被炸了|被击倒了\n",
    "adj = 漂亮的|热的|黑色的|红色的、凉爽的\n",
    "noun = 帽子|汽车|杂志|啤酒|炸鸡|栅栏\n",
    "somewhere = 在医院|在马路|在海边|在泰国|在餐厅\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['他被击倒了热的汽车在海边', '我受伤了漂亮的帽子在泰国', '她受伤了红色的、凉爽的帽子在海边', '一帅哥被击倒了红色的、凉爽的杂志在餐厅', '一美女被炸了红色的、凉爽的啤酒在餐厅', '一小孩被炸了漂亮的杂志在医院', '我受伤了热的啤酒在餐厅', '一帅哥被炸了热的炸鸡在泰国', '一美女被击倒了红色的、凉爽的帽子在马路', '她被击倒了热的汽车在餐厅']\n",
      "[('我受伤了热的啤酒在餐厅', 1.1178051236509418e-28), ('我受伤了漂亮的帽子在泰国', 3.3951840303023593e-32), ('她被击倒了热的汽车在餐厅', 2.4082388905408274e-32), ('他被击倒了热的汽车在海边', 1.0213694451450556e-32), ('一小孩被炸了漂亮的杂志在医院', 8.182455980046385e-37), ('一帅哥被炸了热的炸鸡在泰国', 1.3552754891997064e-37), ('她受伤了红色的、凉爽的帽子在海边', 3.4827526046197345e-41), ('一美女被炸了红色的、凉爽的啤酒在餐厅', 4.9879155327672857e-48), ('一帅哥被击倒了红色的、凉爽的杂志在餐厅', 2.7016909480675114e-50), ('一美女被击倒了红色的、凉爽的帽子在马路', 5.5873821194639434e-52)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('我受伤了热的啤酒在餐厅', 1.1178051236509418e-28)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(create_generate(new_grammar),target='grammar',count=10,callback=three_gram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.基于模式匹配的对话机器人实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pat_match(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    \n",
    "    if is_variable(pattern[0]):\n",
    "        return [(pattern[0], saying[0])] + pat_match(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        if pattern[0] != saying[0]: return []\n",
    "        else:\n",
    "            return pat_match(pattern[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', '3'), ('?Y', '2')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match(\"?X greater than ?Y\".split(), \"3 greater than 2\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsitite(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    \n",
    "    return [parsed_rules.get(rule[0], rule[0])] + subsitite(rule[1:], parsed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_patterns = pat_match(\"I want ?X\".split(), \"I want iPhone\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?X', 'iPhone')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'if', 'you', 'mean', 'if', 'you', 'got', 'a', 'iPhone']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsitite(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs resting\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What if you mean if you got a iPhone'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(subsitite(\"What if you mean if you got a ?X\".split(), pat_to_dict(got_patterns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "john_pat = pat_match('?P needs ?X'.split(), \"John needs vacation\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'does', 'John', 'need', 'vacation', '?']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsitite(\"Why does ?P need ?X ?\".split(), pat_to_dict(john_pat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why does John need vacation ?'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(subsitite(\"Why does ?P need ?X ?\".split(), pat_to_dict(john_pat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(saying,rules):\n",
    "    for k,v in rules.items():\n",
    "        got_patterns = pat_match(k.split(),saying.split())\n",
    "        if got_patterns:\n",
    "            return ' '.join(subsitite(random.choice(v).split(),pat_to_dict(got_patterns)))\n",
    "    return ''\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you need iPhone ?'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I need iPhone',defined_patterns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
